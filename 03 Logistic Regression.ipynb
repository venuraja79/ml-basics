{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4807f7f",
   "metadata": {},
   "source": [
    "# Classification Model to predict Diabetes\n",
    "\n",
    "**Logistic Regression, Cross entropy and Gradient Descent**\n",
    "\n",
    "Diabetes is a life style disease affecting lot of people today. Given age, we will build a model to predict if a person will have diabetes or not. In real life, we will need more variables like glucose level, insulin resistance etc., to do this prediction correctly. \n",
    "\n",
    "The problem is to identify the right category/class a person belongs to given the inputs. The prediction/output is a categorical variable, so this method is known as classification. We have just two categories (yes/no) in this case, the method is known as binary classification. \n",
    "\n",
    "Plan:\n",
    "\n",
    "1. Define a toy dataset (data based approach)\n",
    "2. Introduce Logistic Regression model, sigmoid function\n",
    "3. Introduct Cross-Entropy loss function\n",
    "4. Use Gradient descent for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4e243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the toy dataset\n",
    "X = [10, 20, 25, 35, 21, 54, 68, 75, 20, 80] # Age of the person\n",
    "y = [0, 0, 0, 1, 0, 1, 0, 1, 0, 1]            # 0 - No diabetes, 1 - Has diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9946827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few python package imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd03471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f681a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# People with diabetes are shown in red, and others are in green\n",
    "def plot_data():\n",
    "    # Find all indices where y is 0.\n",
    "    idx_0 = np.where(y==0)\n",
    "    idx_1 = np.where(y==1)\n",
    "    plt.scatter(X[idx_0], y[idx_0], color='green')\n",
    "    plt.scatter(X[idx_1], y[idx_1], color='red')\n",
    "    plt.title('Diabetes Plot')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Has Diabetes?')\n",
    "\n",
    "plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ac70e1",
   "metadata": {},
   "source": [
    "Our data shows that some people are not diabetic even in old age. On the other hand, it is possible to be a diabetic even at an younger age. It will be difficult to handcode a rule to learn this phenomenon. We will try and build a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aeebfd",
   "metadata": {},
   "source": [
    "## We need sigmoid\n",
    "\n",
    "If you look at the output variable it is categorical, and has distinct values. It is either 0 or 1. \n",
    "\n",
    "If you remember, when we trained regression model (y=w.x), we adjusted the value of 'w' until the value of y from the model (yhat) got close to the actual value (y). \n",
    "\n",
    "In the classification case though, we can't use the output of y=wx directly and we have to squash it somehow to bring it closer to either 0 or 1. (classification outputs). This is actually done by this function sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb6d65",
   "metadata": {},
   "source": [
    "The sigmoid function is : $s(x)= \\frac {1}{1+e^{-x}}$\n",
    "\n",
    "Our model is $y=wx+b$ So, after applying sigmoid, model becomes: $s(x)= \\frac {1}{1+e^{-wx+b}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f370820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's implement sigmoid \n",
    "def sigmoid(z):\n",
    "    return 1.0/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e700013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Sigmoid value')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw the sigmoid function\n",
    "zs = []\n",
    "sigs = []\n",
    "for z in np.linspace(-10, 10, 100):\n",
    "    zs.append(z)\n",
    "    sigs.append(sigmoid(z))\n",
    "    \n",
    "plt.scatter(zs, sigs)\n",
    "plt.title(\"Sigmoid Function\")\n",
    "plt.xlabel('Z')\n",
    "plt.ylabel('Sigmoid value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ac0e7",
   "metadata": {},
   "source": [
    "As you can see, sigmoid squashes any numbers between [0 1]. Large negative numbers are squashed to 0, while large positive ones are squashed to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23f9878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid of zero : 0.5 \n",
      "Sigmoid of 1 : 0.7310585786300049 \n",
      "Sigmoid of -1 : 0.2689414213699951 \n"
     ]
    }
   ],
   "source": [
    "# Sigmoid of some numbers\n",
    "print(f\"Sigmoid of zero : {sigmoid(0)} \")\n",
    "print(f\"Sigmoid of 1 : {sigmoid(1)} \")\n",
    "print(f\"Sigmoid of -1 : {sigmoid(-1)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a1c89",
   "metadata": {},
   "source": [
    "## Problem Definition \n",
    "\n",
    "Now, we have defined our model. From our dataset, we have x and y. Our goal is to find the optimal value of parameters (w, b). Now this is similar to our linear regression. \n",
    "\n",
    "Note: This time, we are also including bias (b) as a parameter along with w. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b9a520",
   "metadata": {},
   "source": [
    "This is great, we can apply our loss function/GD based learning framework to find the parameters.\n",
    "\n",
    "**Framework:**\n",
    "1. Assume some initial value for the parameters.\n",
    "2. Using the initial parameters, calculate yhat for all examples in the dataset.\n",
    "3. Calculate the mean loss (all examples in the data) using the loss function.\n",
    "4. Find the gradient of the loss w.r.t the parameters\n",
    "5. Adjust the parameters based on the gradient\n",
    "6. Repeat steps 3 to 5 until convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b918f",
   "metadata": {},
   "source": [
    "## Cross Entropy \n",
    "\n",
    "In the regression training, we used Mean Squared Error (MSE) loss function. However, in the classification case the cross entropy loss function works well. \n",
    "\n",
    "Cross Entropy loss = -$\\frac{1}{n} \\sum_x [y lna + (1−y)ln(1−a)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae4cb72",
   "metadata": {},
   "source": [
    "To understand why this is a good loss function, let's review the below cases.\n",
    "\n",
    "We want our loss to be minimal, when we have our actual value 'y' and our yhat (or 'activation' or 'a') are close to each other. (when yhat ~= y)\n",
    "\n",
    "**Case 1: y = 0 & yhat (or a) ~= 0**:\n",
    "In this case, the first term (ylna) becomes 0. The 2nd term (1-y)ln(1-a) becomes close to zero.\n",
    "\n",
    "**Case 2: y = 1 & yhat (or a) ~= 1.**:\n",
    "In this case, the first term (ylna) becomes close to 0. The 2nd term (1-y)ln(1-a) becomes 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9225864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cross-entropy loss for one example\n",
    "def cross_entropy(act, y):\n",
    "    ce =-((y*np.log(act)) + (1-y)*np.log(1-act))\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a06bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: 0 yhat: 0.10 ce loss: 0.11\n"
     ]
    }
   ],
   "source": [
    "# Case 1:\n",
    "act = 0.1\n",
    "print(f\"y: 0 yhat: {act:.2f} ce loss: {cross_entropy(act, 0):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcb66b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: 0 yhat: 0.95 ce loss: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Case 2:\n",
    "act = 0.95\n",
    "print(f\"y: 0 yhat: {act:.2f} ce loss: {cross_entropy(act, 1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1add2948",
   "metadata": {},
   "source": [
    "### Step 1 : Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525c9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.1\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94f397",
   "metadata": {},
   "source": [
    "### Step 2,3: Calculate CE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2428a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CE loss : {calc_ce_loss(X, y, w, b):.2f}\n"
     ]
    }
   ],
   "source": [
    "def calc_ce_loss(x, y, w, b):\n",
    "    loss = 0\n",
    "    for _x, _y in zip(x, y):\n",
    "        # Calculate sigmoid activation\n",
    "        act = sigmoid(w*_x+b)\n",
    "        \n",
    "        # Calculate CE loss for one example\n",
    "        ce_i = -((_y*np.log(act)) + (1-_y)*np.log(1-act))\n",
    "        loss += ce_i\n",
    "        \n",
    "    # Return average ce loss\n",
    "    return loss/len(y)\n",
    "\n",
    "print(\"Mean CE loss : {calc_ce_loss(X, y, w, b):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052ac65",
   "metadata": {},
   "source": [
    "### Step 4: Calculate Gradient w.r.t parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110d7bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of w: 15.09 and b are : 0.53\n"
     ]
    }
   ],
   "source": [
    "def calc_gradients(x, y, w, b):\n",
    "    dw = 0\n",
    "    db = 0\n",
    "    for _x, _y in zip(x, y):\n",
    "        act = sigmoid(w*_x+b)\n",
    "        # Gradient of w\n",
    "        dw += (act-_y)*_x\n",
    "        # Gradient of b\n",
    "        db += act-_y\n",
    "        \n",
    "    return dw/len(y), db/len(y)\n",
    "\n",
    "dw, db = calc_gradients(X,y,w,b)\n",
    "print(f\"Gradient of w: {dw:.2f} and b are : {db:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4e85e",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8a5b3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 CE Loss: 0.69 Gradient : -4.00 Updated Params: 0.00 -0.00\n",
      "Iteration: 2 CE Loss: 0.68 Gradient : -1.74 Updated Params: 0.01 -0.00\n",
      "Iteration: 3 CE Loss: 0.68 Gradient : -0.78 Updated Params: 0.01 -0.00\n",
      "Iteration: 4 CE Loss: 0.68 Gradient : -0.36 Updated Params: 0.01 -0.00\n",
      "Iteration: 5 CE Loss: 0.68 Gradient : -0.16 Updated Params: 0.01 -0.00\n",
      "Iteration: 6 CE Loss: 0.68 Gradient : -0.08 Updated Params: 0.01 -0.00\n",
      "Iteration: 7 CE Loss: 0.68 Gradient : -0.04 Updated Params: 0.01 -0.00\n",
      "Iteration: 8 CE Loss: 0.68 Gradient : -0.02 Updated Params: 0.01 -0.00\n",
      "Iteration: 9 CE Loss: 0.68 Gradient : -0.01 Updated Params: 0.01 -0.00\n",
      "Iteration: 10 CE Loss: 0.68 Gradient : -0.01 Updated Params: 0.01 -0.00\n",
      "Final parameters w: 0.01 b: -0.00\n"
     ]
    }
   ],
   "source": [
    "# Initial value of parameters\n",
    "w = 0\n",
    "b = 0\n",
    "lr = 0.001   # Learning rate \n",
    "epochs = 10 # Run the learning procedure for epochs\n",
    "for epoch in range(epochs):\n",
    "    loss = calc_ce_loss(X, y, w, b)\n",
    "    dw, db = calc_gradients(X, y, w, b)\n",
    "    w += -lr * dw\n",
    "    b += -lr * db\n",
    "    print(f\"Iteration: {epoch+1} CE Loss: {loss:.2f} Gradient : {dw:.2f} Updated Params: {w:.2f} {b:.2f}\")\n",
    "    \n",
    "print(f\"Final parameters w: {w:.2f} b: {b:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ae8a29",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "815cc5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. of a 60 year old to have diabetes is 0.61\n"
     ]
    }
   ],
   "source": [
    "# What is the probability of a person aged 60 to have diabetes?\n",
    "print(f\"Prob. of a 60 year old to have diabetes is {sigmoid(w*60+b):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be1a71",
   "metadata": {},
   "source": [
    "## Vectorized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b285130",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Simple Logistic Regression Model\n",
    "Vectorized form\n",
    "\n",
    "input data shape : mxn\n",
    "\n",
    "m - number of examples\n",
    "n - number of features\n",
    "'''\n",
    "\n",
    "class SimpleLogisticModel(object):\n",
    "    def __init__(self):\n",
    "        self.weight = None     # Weight\n",
    "        self.bias = None       # bias\n",
    "        self.lr = 0.001        # Learning rate\n",
    "        self.epochs = 500      # Number of epochs to train\n",
    "        \n",
    "    \"\"\"Calculate sigmoid\"\"\"\n",
    "    def _sigmoid(self, z):\n",
    "        return 1.0/(1 + np.exp(-z))  # Shape : m,1\n",
    "    \n",
    "    \"\"\"Calculate cross entropy loss\"\"\"\n",
    "    def calc_loss(self, y, act):\n",
    "        loss = -np.mean(((y*np.log(act)) + (1-y)*np.log(1-act)))\n",
    "        return loss\n",
    "    \n",
    "    \"\"\"Calculate gradients for weight & bias\"\"\"\n",
    "    def calc_gradients(self, X, y, act):\n",
    "        dw = (np.dot(X.T, (act-y))) / len(y)  # Shape: (n , 1)\n",
    "        db = np.mean((act-y))                 # scalar\n",
    "        return dw, db\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape  # m - number of examples, n - no of features\n",
    "        y = y.reshape(-1, 1)  # Shape: (number of examples, 1)\n",
    "        self.weight = np.zeros((n,1)) # Shape: (features , 1)\n",
    "        self.bias = 0\n",
    "        \n",
    "        losses = []\n",
    "        for epoch in range(self.epochs):\n",
    "            act = self._sigmoid(np.dot(X, self.weight) + self.bias)  # Shape: (m, 1)\n",
    "            loss = self.calc_loss(y, act)\n",
    "            dw, db = self.calc_gradients(X, y, act) \n",
    "            self.weight += -self.lr * dw  # shape: n,1\n",
    "            self.bias += -self.lr * db    # scalar\n",
    "            losses.append(loss)\n",
    "        return self.weight, self.bias, losses\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = sigmoid(np.dot(X, self.weight) + self.bias) # Shape: (m,1)\n",
    "        pred_classes = np.array([1 if pred>0.5 else 0 for pred in predictions])\n",
    "        return pred_classes.item(), predictions.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cea9308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicts if a 60 year old will have diabetes : 1 with probability 0.61\n"
     ]
    }
   ],
   "source": [
    "# What is the probability of a person aged 60 to have diabetes?\n",
    "\n",
    "model = SimpleLogisticModel()\n",
    "data_x = np.reshape(X, (-1,1))\n",
    "# Train a model\n",
    "weights, bias, _ = model.fit(data_x, y)\n",
    "\n",
    "# Predict for a new example\n",
    "preds = model.predict(60)\n",
    "preds\n",
    "print(f\"Model predicts if a 60 year old will have diabetes : {preds[0]} with probability {preds[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c939d289",
   "metadata": {},
   "source": [
    "The vectorized implementation can also handle multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "986fd8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weights: [[-0.12266051]\n",
      " [ 0.1291593 ]\n",
      " [-0.02376765]] and bias: -0.04541422288825383 \n",
      "Weights shape: (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# We are creating random dataset with shape 10x3 (mxn)\n",
    "data_3d = np.random.randn(10,3)\n",
    "weights, bias, _ = model.fit(data_3d, y) # Weights shape : n x 1\n",
    "print(f\"Trained Weights: {weights} and bias: {bias} \")\n",
    "print(f\"Weights shape: {weights.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7812b9",
   "metadata": {},
   "source": [
    "In practical applications, we will always train models with a higher level framework such as sklearn, pytorch among others as they support a lot of additional capabilties to pre-process and normalize the data, numerical stability etc.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b546999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
