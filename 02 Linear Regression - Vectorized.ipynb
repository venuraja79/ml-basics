{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9e7a86",
   "metadata": {},
   "source": [
    "## Need for Vectorization\n",
    "\n",
    "Our training procedure implementation in Lecture 1 takes one example at a time (that is the reason for the 'for loop') for processing. In a real-world setting, this is not optimal as is it is time consuming. \n",
    "\n",
    "We can vectorize this step to reduce the cost. Here, we convert the scalars into vectors/matrices and use matrix maths to make these operations faster.\n",
    "\n",
    "Let's look at a concrete example now.\n",
    "\n",
    "For more details on Numpy, refer this great guide.\n",
    "https://betterprogramming.pub/numpy-illustrated-the-visual-guide-to-numpy-3b1d4976de1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4329cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708 µs ± 5.62 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Create a 10K integer list and multiply every number by 2\n",
    "\n",
    "size = 10000\n",
    "\n",
    "num_list = range(size)\n",
    "%timeit num_list_new = [num*2 for num in num_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a14302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.73 µs ± 674 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the list into numpy vector\n",
    "num_vector = np.array(num_list)\n",
    "\n",
    "%timeit num_vector * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb750d",
   "metadata": {},
   "source": [
    "Once we converted the python list into a numpy array, the same multiplication took fraction of the time taken by the for loop.\n",
    "\n",
    "Identifying and refactoring such operations into vector based ones is an important skill to acquire. In this case, we will vectorize the loss and gradient functions to make our regression model training more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf632e2",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/generated/numpy.dot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8916eba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b35776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([2])\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac58577b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6 8]\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "# To perform dot product we need a's last dim should be equal to b's first dim.\n",
    "a = a.reshape(-1, 1)  # Get the shape of a in order\n",
    "print(np.dot(a, b))   # Same as a @ b\n",
    "print(np.dot(a, b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f756a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our toy dataset. Just two python lists\n",
    "X = [25, 30, 40, 20, 15, 60, 33, 52, 70]  # Age\n",
    "y = [65, 70, 78, 60, 45, 70, 65, 65, 60]  # Weight in Kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b64ec029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few python package imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc3bc1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter vector (1 dimensional for now)\n",
    "w = np.array([1])\n",
    "def calculate_loss(self, x, y):\n",
    "    # Vectorized - Taking all examples and do a dot multiply\n",
    "    wx = np.dot(x, w)\n",
    "    loss = ((wx - y) **2).mean()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f90c839",
   "metadata": {},
   "source": [
    "We have removed the for loop with a vector operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d225f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is a vectorized implementation of the simple linear regression model.\n",
    "'''\n",
    "class SimpleRegression():\n",
    "    def __init__(self):\n",
    "        self.params = None # parameter w\n",
    "        self.lr = 0.0002 # Learning rate\n",
    "        self.iterations = 10\n",
    "    \n",
    "    def _calculate_loss(self, x, y):\n",
    "        loss = ((np.dot(x, self.params) - y) **2).mean()\n",
    "        return loss\n",
    "    \n",
    "    def _calculate_gradient(self, x, y):\n",
    "        residue = np.dot(x, self.params) - y\n",
    "        grad = np.dot(x.T, residue)\n",
    "        grad /= len(y)\n",
    "        return grad.item()\n",
    "    \n",
    "    def fit(self, x, targets, iterations=None):\n",
    "        if not iterations:\n",
    "            iterations = self.iterations\n",
    "        self.params = np.ones(x.shape[1])\n",
    "        for _ in range(iterations):\n",
    "            loss = self._calculate_loss(x, targets)\n",
    "            grad = self._calculate_gradient(x, targets)\n",
    "            self.params += -self.lr * grad\n",
    "            print(f\"Loss: {loss:.2f} Gradient : {grad:.2f} Updated params : {self.params.item()}\")\n",
    "            \n",
    "        return self.params\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1dac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 948.56 Gradient : -733.56 Updated params : 1.1467111111111112\n",
      "Loss: 771.68 Gradient : -472.03 Updated params : 1.2411180809876543\n",
      "Loss: 698.44 Gradient : -303.75 Updated params : 1.3018679171368779\n",
      "Loss: 668.12 Gradient : -195.46 Updated params : 1.3409597617007238\n",
      "Loss: 655.56 Gradient : -125.78 Updated params : 1.3661149293237302\n",
      "Loss: 650.36 Gradient : -80.94 Updated params : 1.3823020001872723\n",
      "Loss: 648.21 Gradient : -52.08 Updated params : 1.3927182004316188\n",
      "Loss: 647.31 Gradient : -33.51 Updated params : 1.3994209095532975\n",
      "Loss: 646.94 Gradient : -21.57 Updated params : 1.4037340283985518\n",
      "Loss: 646.79 Gradient : -13.88 Updated params : 1.4065094724519303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.40650947])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(X).astype(float).reshape(-1,1)\n",
    "model = SimpleRegression()\n",
    "model.fit(data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153ff4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.38226522865405"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict weight for a person with age 28\n",
    "model.predict([28])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcccb00",
   "metadata": {},
   "source": [
    "## Broadcasting Intro\n",
    "\n",
    "[Numpy Broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222b9025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  3,  5,  9, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a numpy vector and add a scalar to it.\n",
    "\n",
    "data_s = 2  # scalar\n",
    "data_vec = np.array([2, 1, 3, 7, 8])  # vector\n",
    "data_vec + data_s  # vector + scalar addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfb481c",
   "metadata": {},
   "source": [
    "We just did broadcasting without knowing it. If you closely look at the above addition, numpy allowed us to add a scalar to a vector. i.e, it added every element of the vector by the scalar value. To achieve this simple operation, numpy internally performed 'broadcasting'.\n",
    "\n",
    "Numpy simply created a vector of the shape 'data_vec' by broadcasting the same value across the dimensions.\n",
    "\n",
    "data_s was converted to [2, 2, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9722664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9cd987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  3,  7],\n",
       "       [ 9,  6, 10],\n",
       "       [12,  9, 13]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another example\n",
    "\n",
    "data_2 = np.array([5, 1, 4])\n",
    "data_3 = np.array([[1, 2, 3],[4, 5, 6], [7, 8, 9]])\n",
    "data_3 + data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a7f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data_2.shape)\n",
    "print(data_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb31ff",
   "metadata": {},
   "source": [
    "In this case, numpy copied the variable data_2 three times (row wise) to make the addition possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b07be1ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,4) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m data_4 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m], [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m]])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdata_4\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_2\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,4) (3,) "
     ]
    }
   ],
   "source": [
    "data_4 = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "data_4 + data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b4f0f",
   "metadata": {},
   "source": [
    "The above operation fails because numpy doesn't know how to do the broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01946add",
   "metadata": {},
   "source": [
    "For more details read the excellent explanation provided [here](https://numpy.org/doc/stable/user/basics.broadcasting.html)\n",
    "\n",
    "This is just an introduction to this very important aspect, we will cover this topic in more detail as we move forward. When we get into training models that involves many dimensions (multivariate data, images), any inadvertant broadcasting is very challenging to debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa38a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
